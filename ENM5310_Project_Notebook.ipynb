{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "ENM 5310 Project - Michael Chiou, Stepehen Ching, Quan Vo"
      ],
      "metadata": {
        "id": "kwfUoJ5_6yat"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "flax_CNN.ipynb template from class github"
      ],
      "metadata": {
        "id": "aDX6bvHi65HW"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vd4A3ngazpw0",
        "outputId": "fe17785b-71d7-4c6f-fa88-b28b22c3b017",
        "collapsed": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting typing\n",
            "  Downloading typing-3.7.4.3.tar.gz (78 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/78.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.6/78.6 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[31mERROR: Ignored the following versions that require a different python version: 3.10.0.0 Requires-Python >=2.7, !=3.0.*, !=3.1.*, !=3.2.*, !=3.3.*, <3.5; 3.7.4.2 Requires-Python >=2.7, !=3.0.*, !=3.1.*, !=3.2.*, !=3.3.*, <3.5\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: Could not find a version that satisfies the requirement Tuble (from versions: none)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for Tuble\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "!pip install typing Tuble"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# In this block, modify the imported data to be rotated randomly to get training data\n",
        "# random distribution of 0-180 degrees, apply that rotation to the image and the ground truth angle\n",
        "# i.e. original ground truth vector, rotated by rotation matrix of angle\n",
        "# if angle of unit vector is > 180 or < 0, reflect over x-axis and y-axis to get equivalent/new ground truth"
      ],
      "metadata": {
        "id": "kjHVV1lxEGr2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import glob\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms\n",
        "import matplotlib.pyplot as plt\n",
        "import tifffile as tiff\n",
        "import jax.numpy as jnp\n",
        "from jax import random, vmap, grad, jit\n",
        "from jax.nn import one_hot\n",
        "from PIL import Image\n",
        "import optax\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from typing import Any, Callable, Sequence, Optional, Union, Dict\n",
        "\n",
        "# libraries that we need for image import and processing\n",
        "import skimage\n",
        "import re\n",
        "from pathlib import Path\n",
        "from skimage import io\n",
        "from skimage import filters\n",
        "from skimage import data\n",
        "from scipy.ndimage import rotate\n",
        "# connect w/ the files in drive\n",
        "from google.colab import drive\n",
        "if not os.path.exists('/content/drive'):\n",
        "    drive.mount('/content/drive')\n"
      ],
      "metadata": {
        "id": "ibfatTIddEhg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Setup parameters and connect to the data in the shared drive**"
      ],
      "metadata": {
        "id": "S-7TdV4ioom1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import glob\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tifffile as tiff\n",
        "from tqdm import tqdm\n",
        "import random\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# ==========================================\n",
        "# 1. CONFIGURATION\n",
        "# ==========================================\n",
        "BASE_DIR = '/content/drive/Shareddrives/ENM 5310 Group Project'\n",
        "SOURCE_DIR = os.path.join(BASE_DIR, 'Training Data')\n",
        "OUTPUT_DIR = '/content/drive/Shareddrives/ENM 5310 Group Project/Augmented Data'\n",
        "MODEL_SAVE_DIR = os.path.join(BASE_DIR, 'Models')\n",
        "CSV_FILENAME = 'fibril_orientation_2d_results.csv'\n",
        "\n",
        "for d in [OUTPUT_DIR, MODEL_SAVE_DIR]:\n",
        "    if not os.path.exists(d):\n",
        "        os.makedirs(d)\n",
        "\n",
        "CROP_SIZE = (256, 256)   # (H, W)\n",
        "CROPS_PER_ROTATION = 5\n",
        "ROTATIONS = [0, 90, 180, 270]\n",
        "\n",
        "if not os.path.exists(OUTPUT_DIR):\n",
        "    os.makedirs(OUTPUT_DIR)\n",
        "\n",
        "# ==========================================\n",
        "# 2. HELPER FUNCTIONS\n",
        "# ==========================================\n",
        "def parse_pos(pos_str):\n",
        "    try:\n",
        "        # User specified format: (y, x, 0)\n",
        "        coords = [int(c) for c in pos_str.replace('(', '').replace(')', '').split(',')]\n",
        "        return coords[0], coords[1] # returns y, x\n",
        "    except:\n",
        "        return None, None\n",
        "\n",
        "def rotate_coords_and_vectors(x, y, u, v, img_w, img_h, angle):\n",
        "    \"\"\"\n",
        "    Rotates coordinates and vectors.\n",
        "    Inputs: x (col), y (row), u (x-vec), v (y-vec)\n",
        "    Returns: new_x, new_y, new_u, new_v, new_h, new_w\n",
        "    \"\"\"\n",
        "    if angle == 0:\n",
        "        return x, y, u, v, img_h, img_w\n",
        "\n",
        "    elif angle == 90:\n",
        "        # 90 deg Counter-Clockwise\n",
        "        # Dimensions swap: New W = Old H, New H = Old W\n",
        "        new_w = img_h\n",
        "        new_h = img_w\n",
        "\n",
        "        # Pixel Rotation: (x, y) -> (y, W - 1 - x)\n",
        "        # Note: In array coords, this maps A[y, x] -> A'[new_y, new_x]\n",
        "        # Visual 90 deg CCW:\n",
        "        # new_x (col) = y (old row)\n",
        "        # new_y (row) = (Width - 1) - x (old col)\n",
        "        new_x = y\n",
        "        new_y = (img_w - 1) - x\n",
        "\n",
        "        # Vector Rotation 90 CCW:\n",
        "        # (1,0) Right -> (0,-1) Up (Negative V is Up in image coords)\n",
        "        # (0,1) Down  -> (1,0) Right\n",
        "        # u' = v, v' = -u\n",
        "        new_u = v\n",
        "        new_v = -u\n",
        "        return new_x, new_y, new_u, new_v, new_h, new_w\n",
        "\n",
        "    elif angle == 180:\n",
        "        new_w, new_h = img_w, img_h\n",
        "        # 180 deg\n",
        "        new_x = img_w - 1 - x\n",
        "        new_y = img_h - 1 - y\n",
        "        new_u = -u\n",
        "        new_v = -v\n",
        "        return new_x, new_y, new_u, new_v, new_h, new_w\n",
        "\n",
        "    elif angle == 270:\n",
        "        # 270 deg CCW (or 90 CW)\n",
        "        new_w = img_h\n",
        "        new_h = img_w\n",
        "\n",
        "        # Pixel: (x, y) -> (H - 1 - y, x)\n",
        "        new_x = (img_h - 1) - y\n",
        "        new_y = x\n",
        "\n",
        "        # Vector: 90 CW\n",
        "        # (1,0) Right -> (0,1) Down\n",
        "        # (0,1) Down  -> (-1,0) Left\n",
        "        # u' = -v, v' = u\n",
        "        new_u = -v\n",
        "        new_v = u\n",
        "        return new_x, new_y, new_u, new_v, new_h, new_w\n",
        "\n",
        "def generate_blurred_data(file_list, df, output_subdir):\n",
        "  \"Generate bilteral filter images\"\n",
        "  \"This does not change the ground truth\"\n",
        "  save_path = os.path.join(OUTPUT_DIR, output_subdir)\n",
        "  if not os.path.exists(save_path):\n",
        "    os.makedirs(save_path\n",
        "# ==========================================\n",
        "# 3. MAIN LOOP\n",
        "# ==========================================\n",
        "csv_path = os.path.join(SOURCE_DIR, CSV_FILENAME)\n",
        "df = pd.read_csv(csv_path)\n",
        "df['clean_filename'] = df.iloc[:, 0].apply(lambda x: os.path.basename(str(x)).strip())\n",
        "\n",
        "source_files = sorted(glob.glob(os.path.join(SOURCE_DIR, 'training*.tiff')))\n",
        "new_csv_rows = []\n",
        "\n",
        "print(f\"Generating augmented data from {len(source_files)} images...\")\n",
        "\n",
        "for file_path in tqdm(source_files):\n",
        "    filename = os.path.basename(file_path)\n",
        "    base_name = os.path.splitext(filename)[0]\n",
        "\n",
        "    try:\n",
        "        img = tiff.imread(file_path) # (H, W)\n",
        "    except:\n",
        "        continue\n",
        "\n",
        "    img_labels = df[df['clean_filename'] == filename]\n",
        "\n",
        "    for angle in ROTATIONS:\n",
        "        # A. Rotate Image\n",
        "        k = angle // 90\n",
        "        rot_img = np.rot90(img, k=k)\n",
        "        curr_h, curr_w = rot_img.shape\n",
        "\n",
        "        # B. Rotate Vectors\n",
        "        rotated_labels = []\n",
        "        for _, row in img_labels.iterrows():\n",
        "            pos_y, pos_x = parse_pos(row.iloc[1]) # User said: (y, x, 0)\n",
        "            if pos_x is None: continue\n",
        "\n",
        "            # Pass original W, H for coordinate math\n",
        "            orig_h, orig_w = img.shape\n",
        "\n",
        "            rx, ry, ru, rv, _, _ = rotate_coords_and_vectors(\n",
        "                pos_x, pos_y, row.iloc[2], row.iloc[3], orig_w, orig_h, angle\n",
        "            )\n",
        "            rotated_labels.append({'x': rx, 'y': ry, 'u': ru, 'v': rv})\n",
        "\n",
        "        # C. Random Crops\n",
        "        for i in range(CROPS_PER_ROTATION):\n",
        "            if curr_h < CROP_SIZE[0] or curr_w < CROP_SIZE[1]: continue\n",
        "\n",
        "            y_start = random.randint(0, curr_h - CROP_SIZE[0])\n",
        "            x_start = random.randint(0, curr_w - CROP_SIZE[1])\n",
        "\n",
        "            crop_img = rot_img[y_start:y_start+CROP_SIZE[0], x_start:x_start+CROP_SIZE[1]]\n",
        "\n",
        "            new_filename = f\"{base_name}_rot{angle}_crop{i}.tiff\"\n",
        "            tiff.imwrite(os.path.join(OUTPUT_DIR, new_filename), crop_img)\n",
        "\n",
        "            # Filter labels\n",
        "            for label in rotated_labels:\n",
        "                lx, ly = label['x'], label['y']\n",
        "                if x_start <= lx < x_start + CROP_SIZE[1] and y_start <= ly < y_start + CROP_SIZE[0]:\n",
        "                    new_x = lx - x_start\n",
        "                    new_y = ly - y_start\n",
        "\n",
        "                    new_csv_rows.append({\n",
        "                        'filename': new_filename,\n",
        "                        'pos': f\"({new_y},{new_x},0)\", # Write back as (y, x, 0)\n",
        "                        'u': label['u'],\n",
        "                        'v': label['v']\n",
        "                    })\n",
        "\n",
        "if len(new_csv_rows) > 0:\n",
        "    aug_df = pd.DataFrame(new_csv_rows)\n",
        "    aug_df.to_csv(os.path.join(OUTPUT_DIR, 'augmented_labels.csv'), index=False)\n",
        "    print(\"Synthesis Complete.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        },
        "id": "nqUD3lenDMaX",
        "outputId": "cdbaa9ae-d878-4808-8e37-d825c8fc35da"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generating augmented data from 12 images...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 17%|█▋        | 2/12 [00:54<04:32, 27.23s/it]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2537561751.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    142\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m             \u001b[0mnew_filename\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf\"{base_name}_rot{angle}_crop{i}.tiff\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 144\u001b[0;31m             \u001b[0mtiff\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mOUTPUT_DIR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_filename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcrop_img\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    145\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m             \u001b[0;31m# Filter labels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/tifffile/tifffile.py\u001b[0m in \u001b[0;36mimwrite\u001b[0;34m(file, data, mode, bigtiff, byteorder, imagej, ome, shaped, append, shape, dtype, photometric, planarconfig, extrasamples, volumetric, tile, rowsperstrip, bitspersample, compression, compressionargs, predictor, subsampling, jpegtables, iccprofile, colormap, description, datetime, resolution, resolutionunit, subfiletype, software, metadata, extratags, contiguous, truncate, align, maxworkers, buffersize, returnoffset)\u001b[0m\n\u001b[1;32m   1384\u001b[0m         )\n\u001b[1;32m   1385\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1386\u001b[0;31m     with TiffWriter(\n\u001b[0m\u001b[1;32m   1387\u001b[0m         \u001b[0mfile\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1388\u001b[0m         \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/tifffile/tifffile.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, file, mode, bigtiff, byteorder, append, imagej, ome, shaped)\u001b[0m\n\u001b[1;32m   1698\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_storedshape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1699\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1700\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFileHandle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1701\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mappend\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1702\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fh\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseek\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSEEK_END\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/tifffile/tifffile.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, file, mode, name, offset, size)\u001b[0m\n\u001b[1;32m  13442\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_close\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m  13443\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNullContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m> 13444\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m  13445\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fh\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m  13446\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/tifffile/tifffile.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m  13461\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrealpath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m  13462\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m> 13463\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_mode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m  13464\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_close\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m  13465\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_offset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_offset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**check the raw images**"
      ],
      "metadata": {
        "id": "cu_eJToBo-EZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. RAW IMAGE CHECK\n",
        "# ==========================================\n",
        "def check_raw_images(file_list, num_to_show=3):\n",
        "    print(f\"--- Checking first {num_to_show} raw images ---\")\n",
        "    plt.figure(figsize=(18, 6))\n",
        "\n",
        "    for i in range(min(len(file_list), num_to_show)):\n",
        "        path = file_list[i]\n",
        "        try:\n",
        "            # Load with tifffile to preserve 16-bit/32-bit data\n",
        "            img = tiff.imread(path)\n",
        "\n",
        "            # Normalize for display (Min-Max scaling to 0-1)\n",
        "            img_disp = (img - img.min()) / (img.max() - img.min())\n",
        "\n",
        "            plt.subplot(1, num_to_show, i+1)\n",
        "            plt.imshow(img_disp, cmap='gray') # Use gray for scientific viz\n",
        "            plt.title(f\"{os.path.basename(path)}\\nShape: {img.shape}\\nRange: [{img.min()}, {img.max()}]\")\n",
        "            plt.axis('off')\n",
        "        except Exception as e:\n",
        "            print(f\"Error loading {path}: {e}\")\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "    print(\"---------------------------------------------\")"
      ],
      "metadata": {
        "id": "TdQYINux_yJD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Data Augmentation Class (rotations)**"
      ],
      "metadata": {
        "id": "LVQu3sBSzksc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class PatchRotationAugmentation:\n",
        "  \"\"\"applies rotation transformation to 120x120 patches and the vectors/angle\"\"\"\n",
        "\n",
        "  def = __init__(self, apply_augmentation: bool = True, angle_range: Tuple[float, float]  = (0, 180)):\n",
        "    \"\"\"\n",
        "        Args:\n",
        "            apply_augmentation: if True, applies random rotation\n",
        "            angle_range: (min, max) ration angle in degrees\n",
        "    \"\"\"\n",
        "    self.apply_augmentation = apply_augmentation\n",
        "    self.angle_range = angle_range\n",
        "\n",
        "  def calcualte_max_inscribed_square(self, patch_size: int) -> int:\n",
        "    \"\"\"\n",
        "        Return the size given a max crop of 45 degrees, apply to all patches for consistency\n",
        "        Args:\n",
        "            patch_size: Original patch size (nxn)\n",
        "    \"\"\"\n",
        "    return int(patch_size / np.sqrt(2))\n",
        "\n",
        "  def rotate_patch(self, patch: np.ndarray, angle_deg: float) -> np.ndarray:\n",
        "    \"\"\"\n",
        "        Args:\n",
        "            patch: (H, W) - ideally square\n",
        "            angle_deg: rotation transform in angles\n",
        "        Returns:\n",
        "            rotated and uniformly cropped patch\n",
        "    \"\"\"\n",
        "    original_size = patch.shape[0]\n",
        "    rotated = rotate(patch, angle_deg, reshape=True, order=1, mode='constant', cval=0)\n",
        "    # scipy.ndimage.rotate(), reshape=false ensures the rotated image is mapped onto the orginal image size (120x120), with black corners, the irrelevant corners of the original image are also automatically cropped\n",
        "    # from the new size, select the rows and columns of the rotated image which describe the cropped image for a consistently shaped image of ~(84x84)\n",
        "    inscribed_size = self.calculate_max_inscribed_square(original_size)\n",
        "    new_h, new_w = rotated.shape\n",
        "    start_h = (new_h - inscribed_size) // 2\n",
        "    start_w = (new_w - inscribed_size) // 2\n",
        "    cropped = rotated[start_h:start_h+inscribed_size, start_w:start_w+inscribed_size]\n",
        "    return\n",
        "\n",
        "  def adjust_angle(self, theta: float, rotation_def: float) -> float:\n",
        "    \"\"\"\n",
        "        Args:\n",
        "            theta: original ground truth orientation angle in radians\n",
        "            rotation_deg: applied rotation in degrees\n",
        "        Returns:\n",
        "            adjusted angle in radians, normalized to [-pi/2, pi/2]\n",
        "    \"\"\"\n",
        "    rotation_rad = np.radians(rotation_deg)\n",
        "    # Add rotation to original angle\n",
        "    new_theta = theta + rotation_rad\n",
        "    # Normalize to [-pi/2, pi/2]\n",
        "    new_theta = np.arctan(np.tan(new_theta))\n",
        "    return new_theta\n",
        "\n",
        "  def __call__(self, patch: np.ndarray, theta: float) -> Tuple[np.ndarray, float, float]:\n",
        "    \"\"\"\n",
        "        Apply rotation augmentation to a patch + its ground truth angle\n",
        "        Args:\n",
        "            patch: (H, W) - ideally square\n",
        "            theta: original ground truth orientation angle in radians\n",
        "        Returns:\n",
        "            (rotated_patch, adjusted_theta, applied rotation_deg)\n",
        "    \"\"\"\n",
        "    if not self.apply_augmentation\n",
        "      return patch, theta, 0.0\n",
        "    rotation_deg = np.random.uniform(self.angle_range[0], self.angle_range[1])\n",
        "    rotated_patch = self.rotate_patch(patch, rotation_deg)\n",
        "    adjusted_theta = self.adjust_angle(theta, rotation_deg)\n",
        "    return rotated_patch, adjusted_theta, rotation_deg"
      ],
      "metadata": {
        "id": "T9frNr6czfHR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Final Code:"
      ],
      "metadata": {
        "id": "JohZIJhSO0jw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import glob\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms\n",
        "import matplotlib.pyplot as plt\n",
        "import tifffile as tiff\n",
        "from skimage import exposure\n",
        "import re\n",
        "\n",
        "# 1. GLOBAL CONFIGURATION & SETUP\n",
        "from google.colab import drive\n",
        "if not os.path.exists('/content/drive'):\n",
        "    drive.mount('/content/drive')\n",
        "\n",
        "# Paths\n",
        "BASE_DIR = '/content/drive/Shareddrives/ENM 5310 Group Project'\n",
        "ORIGINAL_DATA_DIR = os.path.join(BASE_DIR, 'Training Data')\n",
        "AUGMENTED_DATA_DIR = '/content/drive/Shareddrives/ENM 5310 Group Project/Augmented Data'\n",
        "SAVE_DIR = '/content/drive/Shareddrives/ENM 5310 Group Project/Models Evaluation'\n",
        "\n",
        "if not os.path.exists(SAVE_DIR):\n",
        "    os.makedirs(SAVE_DIR)\n",
        "\n",
        "# Hyperparameters\n",
        "BATCH_SIZE = 16\n",
        "LR = 5e-4\n",
        "EPOCHS = 20\n",
        "REGION_SIZE = 100\n",
        "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "# Experiment Grid\n",
        "CLAHE_OPTS = [True, False]\n",
        "LOSS_OPTS = ['cosine', 'mse']\n",
        "DEPTH_OPTS = ['deep', 'shallow']\n",
        "\n",
        "# 2. DATASET CLASS\n",
        "class CollagenDataset(Dataset):\n",
        "    def __init__(self, image_files, csv_df, use_clahe):\n",
        "        self.image_files = image_files\n",
        "        self.csv_df = csv_df\n",
        "        self.use_clahe = use_clahe\n",
        "        self.csv_df['clean_filename'] = self.csv_df.iloc[:, 0].apply(lambda x: os.path.basename(str(x)).strip())\n",
        "        self.img_transform = transforms.Compose([transforms.ToTensor()])\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image_files)\n",
        "\n",
        "    def _generate_gt_map(self, filename, shape):\n",
        "        clean_name = os.path.basename(filename).strip()\n",
        "        file_data = self.csv_df[self.csv_df['clean_filename'] == clean_name]\n",
        "\n",
        "        acc_u = np.zeros(shape, dtype=np.float32)\n",
        "        acc_v = np.zeros(shape, dtype=np.float32)\n",
        "        mask = np.zeros(shape, dtype=np.float32)\n",
        "        half = REGION_SIZE // 2\n",
        "\n",
        "        for _, row in file_data.iterrows():\n",
        "            pos_str = row.iloc[1]\n",
        "            try:\n",
        "                coords = [int(c) for c in pos_str.replace('(', '').replace(')', '').split(',')]\n",
        "                cx, cy = coords[0], coords[1]\n",
        "\n",
        "                # Bounds check\n",
        "                y0, y1 = cy - half, cy + half\n",
        "                x0, x1 = cx - half, cx + half\n",
        "                if not (x0 >= 0 and x1 <= shape[1] and y0 >= 0 and y1 <= shape[0]): continue\n",
        "\n",
        "                if 'u' in row: u = float(row['u']); v = float(row['v'])\n",
        "                else: u = float(row.iloc[2]); v = float(row.iloc[3])\n",
        "\n",
        "                mag = np.sqrt(u**2 + v**2)\n",
        "                if mag > 1e-6: u/=mag; v/=mag\n",
        "                if u < 0: u = -u; v = -v\n",
        "\n",
        "                acc_u[y0:y1, x0:x1] += u\n",
        "                acc_v[y0:y1, x0:x1] += v\n",
        "                mask[y0:y1, x0:x1] = 1.0\n",
        "            except: continue\n",
        "\n",
        "        theta = np.arctan(acc_v / (acc_u + 1e-8))\n",
        "        target_sin = np.sin(2 * theta)\n",
        "        target_cos = np.cos(2 * theta)\n",
        "\n",
        "        target_sin[mask == 0] = 0\n",
        "        target_cos[mask == 0] = 0\n",
        "\n",
        "        gt_map = np.stack([target_sin, target_cos], axis=0)\n",
        "        return gt_map, np.expand_dims(mask, axis=0)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        path = self.image_files[idx]\n",
        "        filename = os.path.basename(path)\n",
        "\n",
        "        image = tiff.imread(path).astype(np.float32)\n",
        "\n",
        "        # Min-Max\n",
        "        if image.max() > image.min():\n",
        "            image = (image - image.min()) / (image.max() - image.min())\n",
        "\n",
        "        # CLAHE\n",
        "        if self.use_clahe:\n",
        "            image = exposure.equalize_adapthist(image, kernel_size=None, clip_limit=0.03)\n",
        "            image = image.astype(np.float32)\n",
        "\n",
        "        if len(image.shape) == 2: image = np.expand_dims(image, axis=0)\n",
        "        image_tensor = torch.from_numpy(image)\n",
        "\n",
        "        gt_map, mask = self._generate_gt_map(filename, (image.shape[1], image.shape[2]))\n",
        "\n",
        "        return image_tensor, torch.from_numpy(gt_map), torch.from_numpy(mask), idx\n",
        "\n",
        "# 3. CONFIGURABLE MODEL\n",
        "class ResidualBlock(nn.Module):\n",
        "    def __init__(self, in_c, out_c):\n",
        "        super().__init__()\n",
        "        self.conv = nn.Sequential(\n",
        "            nn.BatchNorm2d(in_c), nn.ReLU(), nn.Conv2d(in_c, out_c, 3, 1, 1),\n",
        "            nn.BatchNorm2d(out_c), nn.ReLU(), nn.Conv2d(out_c, out_c, 3, 1, 1)\n",
        "        )\n",
        "        self.short = nn.Conv2d(in_c, out_c, 1) if in_c != out_c else nn.Identity()\n",
        "    def forward(self, x): return self.short(x) + self.conv(x)\n",
        "\n",
        "class ConfigurableUNet(nn.Module):\n",
        "    def __init__(self, depth='deep'):\n",
        "        super().__init__()\n",
        "        self.depth = depth\n",
        "        self.inc = nn.Sequential(nn.Conv2d(1, 32, 3, 1, 1), nn.ReLU(), nn.Conv2d(32, 32, 3, 1, 1))\n",
        "\n",
        "        self.down1 = nn.Sequential(nn.MaxPool2d(2), ResidualBlock(32, 64))\n",
        "        self.down2 = nn.Sequential(nn.MaxPool2d(2), ResidualBlock(64, 128))\n",
        "\n",
        "        if self.depth == 'deep':\n",
        "            self.down3 = nn.Sequential(nn.MaxPool2d(2), ResidualBlock(128, 256))\n",
        "            self.up2 = nn.ConvTranspose2d(256, 128, 2, 2)\n",
        "            self.conv2 = ResidualBlock(256, 128)\n",
        "\n",
        "        self.up3 = nn.ConvTranspose2d(128, 64, 2, 2)\n",
        "        self.conv3 = ResidualBlock(128, 64)\n",
        "        self.up4 = nn.ConvTranspose2d(64, 32, 2, 2)\n",
        "        self.conv4 = ResidualBlock(64, 32)\n",
        "        self.outc = nn.Conv2d(32, 2, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x1 = self.inc(x)\n",
        "        x2 = self.down1(x1)\n",
        "        x3 = self.down2(x2)\n",
        "\n",
        "        if self.depth == 'deep':\n",
        "            x4 = self.down3(x3)\n",
        "            x = self.up2(x4)\n",
        "            dY = x3.size(2)-x.size(2); dX = x3.size(3)-x.size(3)\n",
        "            x = nn.functional.pad(x, [dX//2, dX-dX//2, dY//2, dY-dY//2])\n",
        "            x = self.conv2(torch.cat([x3, x], 1))\n",
        "        else:\n",
        "            x = x3\n",
        "\n",
        "        x = self.up3(x)\n",
        "        dY = x2.size(2)-x.size(2); dX = x2.size(3)-x.size(3)\n",
        "        x = nn.functional.pad(x, [dX//2, dX-dX//2, dY//2, dY-dY//2])\n",
        "        x = self.conv3(torch.cat([x2, x], 1))\n",
        "\n",
        "        x = self.up4(x)\n",
        "        dY = x1.size(2)-x.size(2); dX = x1.size(3)-x.size(3)\n",
        "        x = nn.functional.pad(x, [dX//2, dX-dX//2, dY//2, dY-dY//2])\n",
        "        x = self.conv4(torch.cat([x1, x], 1))\n",
        "\n",
        "        return F.normalize(self.outc(x), p=2, dim=1)\n",
        "\n",
        "# 4. EVALUATION UTILITIES\n",
        "def get_shortest_angle_diff(angle1, angle2):\n",
        "    diff = np.abs(angle1 - angle2)\n",
        "    diff = diff % 180\n",
        "    diff = np.minimum(diff, 180 - diff)\n",
        "    return diff\n",
        "\n",
        "def evaluate_and_plot(model, loader, model_name):\n",
        "    model.eval()\n",
        "    all_gt, all_pred = [], []\n",
        "\n",
        "    plot_saved = False\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for i, (images, _, _, indices) in enumerate(loader):\n",
        "            outputs = model(images.to(DEVICE))\n",
        "\n",
        "            idx = indices[0].item()\n",
        "            path = loader.dataset.image_files[idx]\n",
        "            filename = os.path.basename(path)\n",
        "\n",
        "            # Prediction Map\n",
        "            sin_map = outputs[0, 0].cpu().numpy()\n",
        "            cos_map = outputs[0, 1].cpu().numpy()\n",
        "            pred_theta = 0.5 * np.arctan2(sin_map, cos_map)\n",
        "\n",
        "            # Extract Vectors\n",
        "            file_data = loader.dataset.csv_df[loader.dataset.csv_df['clean_filename'] == filename]\n",
        "            X, Y, Ug, Vg, Up, Vp = [], [], [], [], [], []\n",
        "            h, w = pred_theta.shape\n",
        "\n",
        "            for _, row in file_data.iterrows():\n",
        "                try:\n",
        "                    c = [int(x) for x in row.iloc[1].replace('(','').replace(')','').split(',')]\n",
        "                    cx, cy = c[0], c[1]\n",
        "                    half = REGION_SIZE // 2\n",
        "                    if not (cx-half>=0 and cx+half<=w and cy-half>=0 and cy+half<=h): continue\n",
        "\n",
        "                    if 'u' in row: u, v = float(row['u']), float(row['v'])\n",
        "                    else: u, v = float(row.iloc[2]), float(row.iloc[3])\n",
        "\n",
        "                    mag = np.sqrt(u**2 + v**2)\n",
        "                    if mag > 1e-6: u/=mag; v/=mag\n",
        "                    if u < 0: u, v = -u, -v\n",
        "\n",
        "                    gt_deg = np.degrees(np.arctan2(v, u + 1e-8))\n",
        "\n",
        "                    th = pred_theta[cy, cx]\n",
        "                    pd_deg = np.degrees(th)\n",
        "                    pu, pv = np.cos(th), np.sin(th)\n",
        "\n",
        "                    all_gt.append(gt_deg)\n",
        "                    all_pred.append(pd_deg)\n",
        "\n",
        "                    X.append(cx); Y.append(cy)\n",
        "                    Ug.append(u); Vg.append(v)\n",
        "                    Up.append(pu); Vp.append(pv)\n",
        "                except: continue\n",
        "\n",
        "            if not plot_saved and len(X) > 0:\n",
        "                img_np = images[0, 0].cpu().numpy()\n",
        "                fig, ax = plt.subplots(1, 2, figsize=(16, 6))\n",
        "                ax[0].imshow(img_np, cmap='gray')\n",
        "                ax[0].quiver(X, Y, Ug, Vg, color='lime', scale=20, pivot='mid')\n",
        "                ax[0].set_title(f\"Ground Truth ({filename})\")\n",
        "\n",
        "                ax[1].imshow(img_np, cmap='gray')\n",
        "                ax[1].quiver(X, Y, Up, Vp, color='red', scale=20, pivot='mid')\n",
        "                ax[1].set_title(f\"Prediction: {model_name}\")\n",
        "\n",
        "                plt.tight_layout()\n",
        "                plt.savefig(os.path.join(SAVE_DIR, f\"{model_name}_Prediction.png\"))\n",
        "                plt.close(fig)\n",
        "                plot_saved = True\n",
        "\n",
        "    # Calculate Metrics\n",
        "    gt_arr = np.array(all_gt)\n",
        "    pd_arr = np.array(all_pred)\n",
        "\n",
        "    errors = get_shortest_angle_diff(gt_arr, pd_arr)\n",
        "    mae = np.mean(errors)\n",
        "    success = np.mean(errors < 15.0) * 100\n",
        "    spread = np.std(pd_arr) / (np.std(gt_arr) + 1e-8)\n",
        "    bias = np.mean(pd_arr) - np.mean(gt_arr)\n",
        "\n",
        "    return [mae, success, spread, bias]\n",
        "\n",
        "# 5. MAIN EXPERIMENT LOOP\n",
        "# Load Files\n",
        "try: df_tr = pd.read_csv(os.path.join(AUGMENTED_DATA_DIR, 'augmented_labels.csv'))\n",
        "except: df_tr = pd.DataFrame()\n",
        "tr_files = sorted(glob.glob(os.path.join(AUGMENTED_DATA_DIR, '*.tiff')))\n",
        "\n",
        "try: df_te = pd.read_csv(os.path.join(ORIGINAL_DATA_DIR, 'fibril_orientation_2d_results.csv'))\n",
        "except: df_te = pd.DataFrame()\n",
        "all_orig = sorted(glob.glob(os.path.join(ORIGINAL_DATA_DIR, 'training*.tiff')))\n",
        "te_files = [f for f in all_orig if int(re.findall(r'\\d+', os.path.basename(f))[0]) >= 10]\n",
        "\n",
        "FINAL_RESULTS = {}\n",
        "\n",
        "print(f\"--- STARTING 8-MODEL COMPARISON ---\")\n",
        "print(f\"Results are saved to: {SAVE_DIR}\")\n",
        "\n",
        "run_count = 1\n",
        "total_runs = 8\n",
        "\n",
        "for clahe in CLAHE_OPTS:\n",
        "    for loss_type in LOSS_OPTS:\n",
        "        for depth in DEPTH_OPTS:\n",
        "\n",
        "            model_name = f\"CLAHE-{clahe}_{loss_type.upper()}_{depth}\"\n",
        "            print(f\"\\n[{run_count}/{total_runs}] Running: {model_name}\")\n",
        "\n",
        "            # 1. Setup Data with specific CLAHE setting\n",
        "            tr_set = CollagenDataset(tr_files, df_tr, use_clahe=clahe)\n",
        "            te_set = CollagenDataset(te_files, df_te, use_clahe=clahe)\n",
        "            tr_load = DataLoader(tr_set, batch_size=BATCH_SIZE, shuffle=True)\n",
        "            te_load = DataLoader(te_set, batch_size=1, shuffle=False)\n",
        "\n",
        "            # 2. Setup Model & Loss\n",
        "            model = ConfigurableUNet(depth=depth).to(DEVICE)\n",
        "            optimizer = optim.Adam(model.parameters(), lr=LR)\n",
        "\n",
        "            if loss_type == 'cosine':\n",
        "                criterion = lambda p, t, m: (1 - (p*t).sum(1, keepdim=True) * m).sum() / (m.sum() + 1e-8)\n",
        "            else:\n",
        "                # MSE on Sin/Cos components\n",
        "                criterion = lambda p, t, m: ((p-t)**2 * m).sum() / (m.sum()*2 + 1e-8)\n",
        "\n",
        "            # 3. Train\n",
        "            losses = []\n",
        "            for epoch in range(EPOCHS):\n",
        "                model.train()\n",
        "                ep_loss = 0\n",
        "                for img, tgt, msk, _ in tr_load:\n",
        "                    img, tgt, msk = img.to(DEVICE), tgt.to(DEVICE), msk.to(DEVICE)\n",
        "                    optimizer.zero_grad()\n",
        "                    loss = criterion(model(img), tgt, msk)\n",
        "                    loss.backward()\n",
        "                    optimizer.step()\n",
        "                    ep_loss += loss.item()\n",
        "                losses.append(ep_loss/len(tr_load))\n",
        "\n",
        "            # Save Loss Curve\n",
        "            plt.figure()\n",
        "            plt.plot(losses)\n",
        "            plt.title(f\"Loss: {model_name}\")\n",
        "            plt.xlabel(\"Epoch\")\n",
        "            plt.ylabel(\"Loss\")\n",
        "            plt.savefig(os.path.join(SAVE_DIR, f\"{model_name}_Loss.png\"))\n",
        "            plt.close()\n",
        "\n",
        "            # 4. Evaluate & Visualize\n",
        "            metrics = evaluate_and_plot(model, te_load, model_name)\n",
        "            FINAL_RESULTS[model_name] = metrics\n",
        "\n",
        "            print(f\"   -> MAE: {metrics[0]:.2f}° | Success: {metrics[1]:.1f}% | Spread: {metrics[2]:.2f}\")\n",
        "            run_count += 1"
      ],
      "metadata": {
        "id": "L_3GudzIAw2A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 6. FINAL SUMMARY GENERATION\n",
        "print(\"\\n--- Final Reports ---\")\n",
        "\n",
        "# Save CSV\n",
        "df_results = pd.DataFrame.from_dict(FINAL_RESULTS, orient='index',\n",
        "                                  columns=['MAE', 'Success_Rate', 'Spread_Ratio', 'Bias'])\n",
        "csv_path = os.path.join(SAVE_DIR, \"All_Models_Comparison_Metrics.csv\")\n",
        "df_results.to_csv(csv_path)\n",
        "print(f\"Metrics CSV saved to: {csv_path}\")\n",
        "\n",
        "# Generate Comparison Plots\n",
        "names = list(FINAL_RESULTS.keys())\n",
        "maes = [FINAL_RESULTS[n][0] for n in names]\n",
        "successs = [FINAL_RESULTS[n][1] for n in names]\n",
        "spreads = [FINAL_RESULTS[n][2] for n in names]\n",
        "\n",
        "fig, ax = plt.subplots(1, 3, figsize=(24, 6))\n",
        "\n",
        "# Plot 1: MAE\n",
        "ax[0].bar(names, maes, color='salmon', edgecolor='black')\n",
        "ax[0].set_title(\"Mean Angular Error (Lower is Better)\")\n",
        "ax[0].set_ylabel(\"Degrees\")\n",
        "ax[0].tick_params(axis='x', rotation=90)\n",
        "ax[0].grid(axis='y', alpha=0.3)\n",
        "\n",
        "# Plot 2: Success Rate\n",
        "ax[1].bar(names, successs, color='skyblue', edgecolor='black')\n",
        "ax[1].set_title(\"Success Rate (<15° error) (Higher is Better)\")\n",
        "ax[1].set_ylabel(\"Percentage %\")\n",
        "ax[1].tick_params(axis='x', rotation=90)\n",
        "ax[1].grid(axis='y', alpha=0.3)\n",
        "\n",
        "# Plot 3: Spread Ratio\n",
        "ax[2].plot(names, spreads, marker='o', linestyle='-', color='purple', linewidth=2)\n",
        "ax[2].axhline(1.0, color='green', linestyle='--', label='Ideal (1.0)')\n",
        "ax[2].axhline(0.1, color='red', linestyle='--', label='Collapse (<0.1)')\n",
        "ax[2].set_title(\"Spread Ratio (Collapse Detector)\")\n",
        "ax[2].set_ylabel(\"Ratio\")\n",
        "ax[2].tick_params(axis='x', rotation=90)\n",
        "ax[2].legend()\n",
        "ax[2].grid(True, alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig(os.path.join(SAVE_DIR, \"All_Models_Comparison_Plots.png\"))\n",
        "plt.show()\n",
        "\n",
        "print(\"Complete.\")"
      ],
      "metadata": {
        "id": "Mp68RXbDjfoI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Adjustable configuration for optimal model (High contrast = True, Cosine Loss Function, Shallow 2-layer U-net)"
      ],
      "metadata": {
        "id": "qhBV9-pBJclo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import glob\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms\n",
        "import matplotlib.pyplot as plt\n",
        "import tifffile as tiff\n",
        "from skimage import exposure\n",
        "\n",
        "# Fixed Settings\n",
        "BATCH_SIZE = 16\n",
        "LR = 5e-4\n",
        "EPOCHS = 25\n",
        "REGION_SIZE = 100\n",
        "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "# Paths\n",
        "ORIGINAL_DATA_DIR = '/content/drive/Shareddrives/ENM 5310 Group Project/Training Data'\n",
        "AUGMENTED_DATA_DIR = '/content/drive/Shareddrives/ENM 5310 Group Project/Augmented Data'\n",
        "\n",
        "# ==========================================\n",
        "# 1. DATASET\n",
        "# ==========================================\n",
        "class CollagenDataset(Dataset):\n",
        "    def __init__(self, image_files, csv_df, use_clahe):\n",
        "        self.image_files = image_files\n",
        "        self.csv_df = csv_df\n",
        "        self.use_clahe = use_clahe\n",
        "        self.csv_df['clean_filename'] = self.csv_df.iloc[:, 0].apply(lambda x: os.path.basename(str(x)).strip())\n",
        "        self.img_transform = transforms.Compose([transforms.ToTensor()])\n",
        "\n",
        "    def __len__(self): return len(self.image_files)\n",
        "\n",
        "    def _generate_gt_map(self, filename, shape):\n",
        "        clean_name = os.path.basename(filename).strip()\n",
        "        file_data = self.csv_df[self.csv_df['clean_filename'] == clean_name]\n",
        "\n",
        "        acc_u = np.zeros(shape, dtype=np.float32)\n",
        "        acc_v = np.zeros(shape, dtype=np.float32)\n",
        "        mask = np.zeros(shape, dtype=np.float32)\n",
        "        half = REGION_SIZE // 2\n",
        "\n",
        "        for _, row in file_data.iterrows():\n",
        "            pos_str = row.iloc[1]\n",
        "            try:\n",
        "                coords = [int(c) for c in pos_str.replace('(', '').replace(')', '').split(',')]\n",
        "                cx, cy = coords[0], coords[1]\n",
        "                y0, y1 = cy - half, cy + half\n",
        "                x0, x1 = cx - half, cx + half\n",
        "                if not (x0>=0 and x1<=shape[1] and y0>=0 and y1<=shape[0]): continue\n",
        "\n",
        "                if 'u' in row: u = float(row['u']); v = float(row['v'])\n",
        "                else: u = float(row.iloc[2]); v = float(row.iloc[3])\n",
        "\n",
        "                mag = np.sqrt(u**2 + v**2)\n",
        "                if mag > 1e-6: u/=mag; v/=mag\n",
        "                if u < 0: u = -u; v = -v\n",
        "\n",
        "                acc_u[y0:y1, x0:x1] += u\n",
        "                acc_v[y0:y1, x0:x1] += v\n",
        "                mask[y0:y1, x0:x1] = 1.0\n",
        "            except: continue\n",
        "\n",
        "        theta = np.arctan(acc_v / (acc_u + 1e-8))\n",
        "        target_sin = np.sin(2 * theta); target_cos = np.cos(2 * theta)\n",
        "        target_sin[mask == 0] = 0; target_cos[mask == 0] = 0\n",
        "\n",
        "        gt_map = np.stack([target_sin, target_cos], axis=0)\n",
        "        return gt_map, np.expand_dims(mask, axis=0)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        path = self.image_files[idx]\n",
        "        image = tiff.imread(path).astype(np.float32)\n",
        "\n",
        "        # --- EXPERIMENT VARIABLE A: PREPROCESSING ---\n",
        "        if image.max() > image.min():\n",
        "            image = (image - image.min()) / (image.max() - image.min())\n",
        "\n",
        "        if self.use_clahe:\n",
        "            image = exposure.equalize_adapthist(image, kernel_size=None, clip_limit=0.03)\n",
        "            image = image.astype(np.float32)\n",
        "        # ---------------------------------------------\n",
        "\n",
        "        if len(image.shape) == 2: image = np.expand_dims(image, axis=0)\n",
        "        img_t = torch.from_numpy(image)\n",
        "        gt, mask = self._generate_gt_map(os.path.basename(path), (image.shape[1], image.shape[2]))\n",
        "        return img_t, torch.from_numpy(gt), torch.from_numpy(mask), idx\n",
        "\n",
        "# ==========================================\n",
        "# 2. MODELS\n",
        "# ==========================================\n",
        "class ResidualBlock(nn.Module):\n",
        "    def __init__(self, in_c, out_c):\n",
        "        super().__init__()\n",
        "        self.conv = nn.Sequential(nn.BatchNorm2d(in_c), nn.ReLU(),\n",
        "                                  nn.Conv2d(in_c, out_c, 3, 1, 1),\n",
        "                                  nn.BatchNorm2d(out_c), nn.ReLU(),\n",
        "                                  nn.Conv2d(out_c, out_c, 3, 1, 1))\n",
        "        self.short = nn.Conv2d(in_c, out_c, 1) if in_c != out_c else nn.Identity()\n",
        "    def forward(self, x): return self.short(x) + self.conv(x)\n",
        "\n",
        "class ConfigurableUNet(nn.Module):\n",
        "    def __init__(self, depth='deep'):\n",
        "        super().__init__()\n",
        "        self.depth = depth\n",
        "        self.inc = nn.Sequential(nn.Conv2d(1, 32, 3, 1, 1), nn.ReLU(), nn.Conv2d(32, 32, 3, 1, 1))\n",
        "\n",
        "        # --- EXPERIMENT VARIABLE C: DEPTH ---\n",
        "        self.down1 = nn.Sequential(nn.MaxPool2d(2), ResidualBlock(32, 64))\n",
        "        self.down2 = nn.Sequential(nn.MaxPool2d(2), ResidualBlock(64, 128))\n",
        "\n",
        "        if self.depth == 'deep':\n",
        "            self.down3 = nn.Sequential(nn.MaxPool2d(2), ResidualBlock(128, 256))\n",
        "            self.up2 = nn.ConvTranspose2d(256, 128, 2, 2)\n",
        "            self.conv2 = ResidualBlock(256, 128)\n",
        "\n",
        "        self.up3 = nn.ConvTranspose2d(128, 64, 2, 2)\n",
        "        self.conv3 = ResidualBlock(128, 64)\n",
        "        self.up4 = nn.ConvTranspose2d(64, 32, 2, 2)\n",
        "        self.conv4 = ResidualBlock(64, 32)\n",
        "        self.outc = nn.Conv2d(32, 2, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x1 = self.inc(x)\n",
        "        x2 = self.down1(x1)\n",
        "        x3 = self.down2(x2)\n",
        "\n",
        "        if self.depth == 'deep':\n",
        "            x4 = self.down3(x3)\n",
        "            # Up\n",
        "            x = self.up2(x4)\n",
        "            dY = x3.size(2)-x.size(2); dX = x3.size(3)-x.size(3)\n",
        "            x = nn.functional.pad(x, [dX//2, dX-dX//2, dY//2, dY-dY//2])\n",
        "            x = self.conv2(torch.cat([x3, x], 1))\n",
        "        else:\n",
        "            x = x3\n",
        "\n",
        "        x = self.up3(x)\n",
        "        dY = x2.size(2)-x.size(2); dX = x2.size(3)-x.size(3)\n",
        "        x = nn.functional.pad(x, [dX//2, dX-dX//2, dY//2, dY-dY//2])\n",
        "        x = self.conv3(torch.cat([x2, x], 1))\n",
        "\n",
        "        x = self.up4(x)\n",
        "        dY = x1.size(2)-x.size(2); dX = x1.size(3)-x.size(3)\n",
        "        x = nn.functional.pad(x, [dX//2, dX-dX//2, dY//2, dY-dY//2])\n",
        "        x = self.conv4(torch.cat([x1, x], 1))\n",
        "\n",
        "        # Normalize to Unit Vector\n",
        "        return F.normalize(self.outc(x), p=2, dim=1)\n",
        "\n",
        "# ==========================================\n",
        "# 3. METRIC CALCULATION HELPERS\n",
        "# ==========================================\n",
        "def get_shortest_angle_diff(angle1, angle2):\n",
        "    \"\"\"\n",
        "    Calculates the smallest difference between two angles in degrees,\n",
        "    accounting for 180-degree (pi radian) symmetry of fibers.\n",
        "    \"\"\"\n",
        "    # Convert input to radians if they are in degrees, or handle as radians\n",
        "    # Assuming inputs are already in degrees for this helper\n",
        "    diff = np.abs(angle1 - angle2)\n",
        "    diff = diff % 180  # Normalize to [0, 180]\n",
        "    diff = np.minimum(diff, 180 - diff) # Distance to nearest 180 multiple\n",
        "    return diff\n",
        "\n",
        "def calculate_metrics(gt_angles, pred_angles):\n",
        "    \"\"\"\n",
        "    Computes the 4 key metrics from raw angle arrays (in degrees).\n",
        "    \"\"\"\n",
        "    # 1. Angular Errors (Absolute)\n",
        "    errors = get_shortest_angle_diff(gt_angles, pred_angles)\n",
        "    mae = np.mean(errors)\n",
        "\n",
        "    # 2. Success Rate (Tolerance < 15 degrees)\n",
        "    success_rate = np.mean(errors < 15.0) * 100\n",
        "\n",
        "    # 3. Spread Ratio (Pred Std / GT Std)\n",
        "    # Measures if the model has collapsed (Ratio < 0.1)\n",
        "    std_gt = np.std(gt_angles)\n",
        "    std_pred = np.std(pred_angles)\n",
        "    spread_ratio = std_pred / (std_gt + 1e-8)\n",
        "\n",
        "    # 4. Bias (Signed Mean Error)\n",
        "    # Simple mean difference (approximate for circular data but useful for trend)\n",
        "    bias = np.mean(pred_angles) - np.mean(gt_angles)\n",
        "\n",
        "    return {\n",
        "        \"MAE (deg)\": mae,\n",
        "        \"Success Rate (%)\": success_rate,\n",
        "        \"Spread Ratio\": spread_ratio,\n",
        "        \"Bias (deg)\": bias\n",
        "    }\n",
        "\n",
        "# ==========================================\n",
        "# 4. COMPREHENSIVE EVALUATION FUNCTION\n",
        "# ==========================================\n",
        "def evaluate_model_comprehensive(model, loader, device='cuda', num_show=3):\n",
        "    model.eval()\n",
        "\n",
        "    all_gt_angles = []\n",
        "    all_pred_angles = []\n",
        "\n",
        "    print(\"\\n--- Starting Comprehensive Evaluation ---\")\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for i, (images, _, _, indices) in enumerate(loader):\n",
        "            images_dev = images.to(device)\n",
        "            outputs = model(images_dev)\n",
        "\n",
        "            # Extract Batch Info\n",
        "            idx = indices[0].item()\n",
        "            path = loader.dataset.image_files[idx]\n",
        "            filename = os.path.basename(path)\n",
        "\n",
        "            # Unpack Prediction Map (Sin/Cos -> Angle)\n",
        "            sin_map = outputs[0, 0].cpu().numpy()\n",
        "            cos_map = outputs[0, 1].cpu().numpy()\n",
        "            pred_theta_map = 0.5 * np.arctan2(sin_map, cos_map) # Radians [-pi/2, pi/2]\n",
        "\n",
        "            # Get Ground Truth Vectors from CSV\n",
        "            file_data = loader.dataset.csv_df[loader.dataset.csv_df['clean_filename'] == filename]\n",
        "\n",
        "            X_list, Y_list = [], []\n",
        "            U_gt_list, V_gt_list = [], []\n",
        "            U_pd_list, V_pd_list = [], []\n",
        "\n",
        "            h, w = pred_theta_map.shape\n",
        "\n",
        "            for _, row in file_data.iterrows():\n",
        "                try:\n",
        "                    # Parse Grid Position\n",
        "                    c = [int(x) for x in row.iloc[1].replace('(', '').replace(')', '').split(',')]\n",
        "                    cx, cy = c[0], c[1]\n",
        "\n",
        "                    # Bounds Check\n",
        "                    half = 100 // 2 # Region Size\n",
        "                    if not (cx-half >= 0 and cx+half <= w and cy-half >= 0 and cy+half <= h):\n",
        "                        continue\n",
        "\n",
        "                    # 1. Process Ground Truth\n",
        "                    if 'u' in row: u, v = float(row['u']), float(row['v'])\n",
        "                    else: u, v = float(row.iloc[2]), float(row.iloc[3])\n",
        "\n",
        "                    # Normalize & Force Right Half-Plane (Symmetry)\n",
        "                    mag = np.sqrt(u**2 + v**2)\n",
        "                    if mag > 1e-6: u /= mag; v /= mag\n",
        "                    if u < 0: u = -u; v = -v\n",
        "\n",
        "                    gt_angle_deg = np.degrees(np.arctan2(v, u + 1e-8))\n",
        "\n",
        "                    # 2. Process Prediction (Sample at center)\n",
        "                    pred_rad = pred_theta_map[cy, cx]\n",
        "                    pred_angle_deg = np.degrees(pred_rad)\n",
        "\n",
        "                    pu, pv = np.cos(pred_rad), np.sin(pred_rad)\n",
        "\n",
        "                    # Store for Metrics\n",
        "                    all_gt_angles.append(gt_angle_deg)\n",
        "                    all_pred_angles.append(pred_angle_deg)\n",
        "\n",
        "                    # Store for Plotting\n",
        "                    X_list.append(cx); Y_list.append(cy)\n",
        "                    U_gt_list.append(u); V_gt_list.append(v)\n",
        "                    U_pd_list.append(pu); V_pd_list.append(pv)\n",
        "\n",
        "                except: continue\n",
        "\n",
        "            # --- Visualization (Only show first 'num_show' images) ---\n",
        "            if i < num_show:\n",
        "                img_np = images[0, 0].cpu().numpy()\n",
        "                fig, ax = plt.subplots(1, 2, figsize=(18, 5))\n",
        "\n",
        "                # Ground Truth\n",
        "                ax[0].imshow(img_np, cmap='gray')\n",
        "                ax[0].quiver(X_list, Y_list, U_gt_list, V_gt_list, color='lime', scale=20, pivot='mid', headaxislength=0)\n",
        "                ax[0].set_title(f\"Ground Truth: {filename}\")\n",
        "\n",
        "                # Prediction\n",
        "                ax[1].imshow(img_np, cmap='gray')\n",
        "                ax[1].quiver(X_list, Y_list, U_pd_list, V_pd_list, color='red', scale=20, pivot='mid', headaxislength=0)\n",
        "                ax[1].set_title(f\"Prediction: {filename}\")\n",
        "\n",
        "                plt.show()\n",
        "\n",
        "    # --- Final Metric Calculation ---\n",
        "    results = calculate_metrics(np.array(all_gt_angles), np.array(all_pred_angles))\n",
        "\n",
        "    print(\"\\n\" + \"=\"*40)\n",
        "    print(f\"FINAL RESULTS (Evaluated on {len(all_gt_angles)} vectors)\")\n",
        "    print(\"=\"*40)\n",
        "    print(f\"Mean Angular Error:   {results['MAE (deg)']:.2f}°  (Lower is better)\")\n",
        "    print(f\"Success Rate (<15°):  {results['Success Rate (%)']:.1f}%   (Higher is better)\")\n",
        "    print(f\"Spread Ratio:         {results['Spread Ratio']:.2f}    (Target ~1.0. <0.1 means collapse)\")\n",
        "    print(f\"Bias:                 {results['Bias (deg)']:.2f}°   (Signed error)\")\n",
        "    print(\"=\"*40 + \"\\n\")\n",
        "\n",
        "    return results\n",
        "\n",
        "# ==========================================\n",
        "# 5. EXPERIMENT PLAYGROUND\n",
        "# ==========================================\n",
        "# Variable A: Preprocessing\n",
        "USE_CLAHE = True       # True = Enhance contrast. False = Raw intensity.\n",
        "\n",
        "# Variable B: Loss Function\n",
        "# 'cosine' = Vector similarity (Smooth). 'mse' = Direct angle error (Harder).\n",
        "LOSS_TYPE = 'cosine'\n",
        "\n",
        "# Variable C: Model Complexity\n",
        "MODEL_DEPTH = 'shallow'   # 'deep' = Standard 4-level U-Net. 'shallow' = Fast 2-level U-Net.\n",
        "\n",
        "# 6. EXECUTION\n",
        "# ==========================================\n",
        "# Load\n",
        "try: df_tr = pd.read_csv(os.path.join(AUGMENTED_DATA_DIR, 'augmented_labels.csv'))\n",
        "except: df_tr = pd.DataFrame()\n",
        "tr_files = sorted(glob.glob(os.path.join(AUGMENTED_DATA_DIR, '*.tiff')))\n",
        "\n",
        "try: df_te = pd.read_csv(os.path.join(ORIGINAL_DATA_DIR, 'fibril_orientation_2d_results.csv'))\n",
        "except: df_te = pd.DataFrame()\n",
        "all_orig = sorted(glob.glob(os.path.join(ORIGINAL_DATA_DIR, 'training*.tiff')))\n",
        "import re\n",
        "te_files = [f for f in all_orig if int(re.findall(r'\\d+', os.path.basename(f))[0]) >= 10]\n",
        "\n",
        "tr_set = CollagenDataset(tr_files, df_tr, use_clahe=USE_CLAHE)\n",
        "te_set = CollagenDataset(te_files, df_te, use_clahe=USE_CLAHE)\n",
        "tr_load = DataLoader(tr_set, batch_size=BATCH_SIZE, shuffle=True)\n",
        "te_load = DataLoader(te_set, batch_size=1, shuffle=False)\n",
        "\n",
        "print(f\"--- RUNNING EXPERIMENT ---\")\n",
        "print(f\"CLAHE: {USE_CLAHE} | LOSS: {LOSS_TYPE} | DEPTH: {MODEL_DEPTH}\")\n",
        "print(f\"Training on {len(tr_files)} images...\")\n",
        "\n",
        "model = ConfigurableUNet(depth=MODEL_DEPTH).to(DEVICE)\n",
        "optimizer = optim.Adam(model.parameters(), lr=LR)\n",
        "\n",
        "# --- EXPERIMENT VARIABLE B: LOSS ---\n",
        "if LOSS_TYPE == 'cosine':\n",
        "    # 1 - Cosine Similarity\n",
        "    criterion = lambda p, t, m: (1 - (p*t).sum(1, keepdim=True) * m).sum() / (m.sum() + 1e-8)\n",
        "else:\n",
        "    # MSE Loss\n",
        "    criterion = lambda p, t, m: ((p-t)**2 * m).sum() / (m.sum()*2 + 1e-8)\n",
        "\n",
        "losses = []\n",
        "for epoch in range(EPOCHS):\n",
        "    model.train()\n",
        "    ep_loss = 0\n",
        "    for img, tgt, msk, _ in tr_load:\n",
        "        img, tgt, msk = img.to(DEVICE), tgt.to(DEVICE), msk.to(DEVICE)\n",
        "        optimizer.zero_grad()\n",
        "        loss = criterion(model(img), tgt, msk)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        ep_loss += loss.item()\n",
        "    print(f\"Ep {epoch+1}: Loss={ep_loss/len(tr_load):.4f}\")\n",
        "    losses.append(ep_loss/len(tr_load))\n",
        "\n",
        "plt.plot(losses); plt.title(f\"Loss Curve ({LOSS_TYPE})\"); plt.show()\n",
        "\n",
        "# Visualizer (No Changes)\n",
        "def viz(model, loader):\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        for _, (images, _, _, indices) in enumerate(loader):\n",
        "            out = model(images.to(DEVICE))\n",
        "            path = loader.dataset.image_files[indices[0].item()]\n",
        "            name = os.path.basename(path)\n",
        "\n",
        "            sin_map = out[0, 0].cpu().numpy(); cos_map = out[0, 1].cpu().numpy()\n",
        "            p_theta = 0.5 * np.arctan2(sin_map, cos_map)\n",
        "\n",
        "            # Extract Grid\n",
        "            file_data = loader.dataset.csv_df[loader.dataset.csv_df['clean_filename'] == name]\n",
        "            X, Y, Ug, Vg, Up, Vp = [], [], [], [], [], []\n",
        "            h, w = p_theta.shape\n",
        "\n",
        "            for _, row in file_data.iterrows():\n",
        "                try:\n",
        "                    c = [int(x) for x in row.iloc[1].replace('(','').replace(')','').split(',')]\n",
        "                    cx, cy = c[0], c[1]\n",
        "                    if not (0<=cx<w and 0<=cy<h): continue\n",
        "\n",
        "                    # GT\n",
        "                    u = float(row.iloc[2]); v = float(row.iloc[3])\n",
        "                    m = np.sqrt(u**2+v**2)\n",
        "                    if m > 1e-6: u/=m; v/=m\n",
        "\n",
        "                    # Pred\n",
        "                    th = p_theta[cy, cx]\n",
        "                    pu, pv = np.cos(th), np.sin(th)\n",
        "\n",
        "                    X.append(cx); Y.append(cy)\n",
        "                    Ug.append(u); Vg.append(v)\n",
        "                    Up.append(pu); Vp.append(pv)\n",
        "                except: continue\n",
        "\n",
        "            img_np = images[0, 0].cpu().numpy()\n",
        "            f, ax = plt.subplots(1, 2, figsize=(15, 5))\n",
        "            ax[0].imshow(img_np, cmap='gray'); ax[0].quiver(X, Y, Ug, Vg, color='lime', scale=20, pivot='mid')\n",
        "            ax[0].set_title(\"Ground Truth\")\n",
        "            ax[1].imshow(img_np, cmap='gray'); ax[1].quiver(X, Y, Up, Vp, color='red', scale=20, pivot='mid')\n",
        "            ax[1].set_title(f\"Prediction ({LOSS_TYPE}, {MODEL_DEPTH})\")\n",
        "            plt.show()\n",
        "\n",
        "if len(te_files) > 0: viz(model, te_load)"
      ],
      "metadata": {
        "id": "_b4muG7_JmG2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "New code for comparing different ways to augment the data"
      ],
      "metadata": {
        "id": "nqhoLVxBfil6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import glob\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import tifffile as tiff\n",
        "from skimage import exposure, restoration\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tqdm import tqdm\n",
        "import random\n",
        "\n",
        "# ==========================================\n",
        "# 1. CONFIGURATION\n",
        "# ==========================================\n",
        "# Adjust these paths to your specific Drive folder structure\n",
        "BASE_DIR = '/content/drive/Shareddrives/ENM 5310 Group Project'\n",
        "ORIGINAL_DATA_DIR = os.path.join(BASE_DIR, 'Training Data')\n",
        "AUG_OUTPUT_DIR = os.path.join(BASE_DIR, 'Experiment_Data_v2')\n",
        "MODEL_SAVE_DIR = os.path.join(BASE_DIR, 'Models_v2')\n",
        "CSV_FILENAME = 'fibril_orientation_2d_results.csv'\n",
        "\n",
        "# Hyperparameters\n",
        "BATCH_SIZE = 16\n",
        "LR = 5e-4\n",
        "EPOCHS = 15 # Reduced slightly for speed in this demo\n",
        "REGION_SIZE = 100 # This is for GT map generation\n",
        "FIXED_IMAGE_SIZE = 256 # Define a fixed square size for image inputs to the model\n",
        "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "for d in [AUG_OUTPUT_DIR, MODEL_SAVE_DIR]:\n",
        "    if not os.path.exists(d):\n",
        "        os.makedirs(d)\n"
      ],
      "metadata": {
        "id": "3-ocTsu2feuv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "new_cell_1"
      },
      "source": [
        "# ==========================================\n",
        "# 2. DATA AUGMENTATION FUNCTIONS\n",
        "# ==========================================\n",
        "\n",
        "def parse_pos(pos_str):\n",
        "    \"\"\"Parses (y, x, 0) string from CSV.\"\"\"\n",
        "    try:\n",
        "        coords = [int(c) for c in pos_str.replace('(', '').replace(')', '').split(',')]\n",
        "        return coords[0], coords[1] # y, x\n",
        "    except:\n",
        "        return None, None\n",
        "\n",
        "def generate_rotated_data(file_list, df, output_subdir, fixed_size=FIXED_IMAGE_SIZE):\n",
        "    \"\"\"Generates rotated and center-cropped images and updates vector labels.\"\"\"\n",
        "    save_path = os.path.join(AUG_OUTPUT_DIR, output_subdir)\n",
        "    if not os.path.exists(save_path): os.makedirs(save_path)\n",
        "\n",
        "    new_csv_rows = []\n",
        "    print(f\"Generating Rotated Data in {output_subdir}...\")\n",
        "\n",
        "    for file_path in tqdm(file_list):\n",
        "        filename = os.path.basename(file_path)\n",
        "        base_name = os.path.splitext(filename)[0]\n",
        "        try: img = tiff.imread(file_path)\n",
        "        except: continue\n",
        "\n",
        "        orig_h, orig_w = img.shape\n",
        "        img_labels = df[df['clean_filename'] == filename]\n",
        "\n",
        "        for angle in [0, 90]: # Using 0 and 90 degree rotations\n",
        "            # 1. Rotate Image\n",
        "            k = angle // 90\n",
        "            rot_img = np.rot90(img, k=k)\n",
        "            curr_h, curr_w = rot_img.shape\n",
        "\n",
        "            # Center crop the rotated image to a fixed size\n",
        "            if curr_h < fixed_size or curr_w < fixed_size:\n",
        "                # If image is smaller than fixed_size, pad it\n",
        "                pad_h_before = (fixed_size - curr_h) // 2\n",
        "                pad_h_after = fixed_size - curr_h - pad_h_before\n",
        "                pad_w_before = (fixed_size - curr_w) // 2\n",
        "                pad_w_after = fixed_size - curr_w - pad_w_before\n",
        "                cropped_img = np.pad(rot_img, ((pad_h_before, pad_h_after), (pad_w_before, pad_w_after)), mode='constant')\n",
        "            else:\n",
        "                # Center crop\n",
        "                y_start = (curr_h - fixed_size) // 2\n",
        "                x_start = (curr_w - fixed_size) // 2\n",
        "                cropped_img = rot_img[y_start:y_start+fixed_size, x_start:x_start+fixed_size]\n",
        "\n",
        "            # Save the cropped image for this rotation\n",
        "            new_img_name = f\"{base_name}_rot{angle}.tiff\"\n",
        "            tiff.imwrite(os.path.join(save_path, new_img_name), cropped_img)\n",
        "\n",
        "            # 2. Rotate and Adjust Vectors\n",
        "            # Calculate the offsets for cropping from the rotated image\n",
        "            crop_offset_y = (curr_h - fixed_size) // 2\n",
        "            crop_offset_x = (curr_w - fixed_size) // 2\n",
        "\n",
        "            for _, row in img_labels.iterrows():\n",
        "                py, px = parse_pos(row.iloc[1]) # original coords relative to original image\n",
        "                if px is None: continue\n",
        "\n",
        "                # Get coords and vectors in the *rotated* image frame (before cropping)\n",
        "                rx_rot, ry_rot = px, py\n",
        "                ru_rot, rv_rot = float(row.iloc[2]), float(row.iloc[3])\n",
        "\n",
        "                if angle == 90:\n",
        "                    # For 90 deg CCW rotation:\n",
        "                    # New X = Old Y\n",
        "                    # New Y = (Original Width - 1) - Old X\n",
        "                    # New U = Old V\n",
        "                    # New V = -Old U\n",
        "                    rx_rot = py\n",
        "                    ry_rot = (orig_w - 1) - px\n",
        "                    ru_rot = float(row.iloc[3])\n",
        "                    rv_rot = -float(row.iloc[2])\n",
        "\n",
        "                # Now, adjust these (rx_rot, ry_rot) for the cropping to fixed_size\n",
        "                # These coordinates are relative to the top-left of the rotated image\n",
        "                rx_cropped = rx_rot - crop_offset_x\n",
        "                ry_cropped = ry_rot - crop_offset_y\n",
        "\n",
        "                # Only add label if it falls within the *fixed_size* cropped region\n",
        "                if 0 <= rx_cropped < fixed_size and 0 <= ry_cropped < fixed_size:\n",
        "                    new_csv_rows.append({\n",
        "                        'filename': new_img_name,\n",
        "                        'pos': f\"({int(ry_cropped)},{int(rx_cropped)},0)\",\n",
        "                        'u': ru_rot,\n",
        "                        'v': rv_rot\n",
        "                    })\n",
        "\n",
        "    out_df = pd.DataFrame(new_csv_rows)\n",
        "    out_df.to_csv(os.path.join(save_path, 'labels.csv'), index=False)\n",
        "    return save_path\n",
        "\n",
        "def generate_blurred_data(file_list, df, output_subdir, fixed_size=FIXED_IMAGE_SIZE):\n",
        "    \"\"\"\n",
        "    Generates Bilateral Filtered images and ensures fixed output size.\n",
        "    Note: Blurring does NOT change vector direction or coordinates.\n",
        "    \"\"\"\n",
        "    save_path = os.path.join(AUG_OUTPUT_DIR, output_subdir)\n",
        "    if not os.path.exists(save_path): os.makedirs(save_path)\n",
        "\n",
        "    new_csv_rows = []\n",
        "    print(f\"Generating Blurred Data in {output_subdir}...\")\n",
        "\n",
        "    for file_path in tqdm(file_list):\n",
        "        filename = os.path.basename(file_path)\n",
        "        base_name = os.path.splitext(filename)[0]\n",
        "        try: img = tiff.imread(file_path)\n",
        "        except: continue\n",
        "\n",
        "        orig_h, orig_w = img.shape\n",
        "\n",
        "        # Normalize for skimage float requirement\n",
        "        img_norm = (img - img.min()) / (img.max() - img.min() + 1e-8) # Added epsilon to prevent division by zero\n",
        "\n",
        "        # Apply Bilateral Filter\n",
        "        blurred_img = restoration.denoise_bilateral(\n",
        "            img_norm, sigma_color=0.1, sigma_spatial=5, channel_axis=None\n",
        "        )\n",
        "\n",
        "        # Rescale back to original range (assuming original was 16-bit tiff)\n",
        "        blurred_img = (blurred_img * 65535).astype(np.uint16)\n",
        "\n",
        "        # Center crop the blurred image to a fixed size\n",
        "        curr_h, curr_w = blurred_img.shape\n",
        "        if curr_h < fixed_size or curr_w < fixed_size:\n",
        "            pad_h_before = (fixed_size - curr_h) // 2\n",
        "            pad_h_after = fixed_size - curr_h - pad_h_before\n",
        "            pad_w_before = (fixed_size - curr_w) // 2\n",
        "            pad_w_after = fixed_size - curr_w - pad_w_before\n",
        "            cropped_img = np.pad(blurred_img, ((pad_h_before, pad_h_after), (pad_w_before, pad_w_after)), mode='constant')\n",
        "        else:\n",
        "            y_start = (curr_h - fixed_size) // 2\n",
        "            x_start = (curr_w - fixed_size) // 2\n",
        "            cropped_img = blurred_img[y_start:y_start+fixed_size, x_start:x_start+fixed_size]\n",
        "\n",
        "        new_img_name = f\"blur_{base_name}.tiff\"\n",
        "        tiff.imwrite(os.path.join(save_path, new_img_name), cropped_img)\n",
        "\n",
        "        # Copy labels exactly (vectors don't change with blur), but adjust for crop\n",
        "        img_labels = df[df['clean_filename'] == filename]\n",
        "\n",
        "        # Calculate the offsets for cropping from the original image (which matches blurred_img size before crop)\n",
        "        crop_offset_y = (orig_h - fixed_size) // 2\n",
        "        crop_offset_x = (orig_w - fixed_size) // 2\n",
        "\n",
        "        for _, row in img_labels.iterrows():\n",
        "            new_row = row.to_dict()\n",
        "            new_row['filename'] = new_img_name\n",
        "            # Ensure u/v are explicitly set if they were positional in original csv\n",
        "            if 'u' not in new_row:\n",
        "                new_row['u'] = row.iloc[2]\n",
        "                new_row['v'] = row.iloc[3]\n",
        "\n",
        "            py, px = parse_pos(row.iloc[1]) # original coords relative to original image\n",
        "            if px is None: continue\n",
        "\n",
        "            # Adjust coordinates for the cropping\n",
        "            px_cropped = px - crop_offset_x\n",
        "            py_cropped = py - crop_offset_y\n",
        "\n",
        "            # Only add label if it falls within the *fixed_size* cropped region\n",
        "            if 0 <= px_cropped < fixed_size and 0 <= py_cropped < fixed_size:\n",
        "                new_row['pos'] = f\"({int(py_cropped)},{int(px_cropped)},0)\"\n",
        "                new_csv_rows.append(new_row)\n",
        "\n",
        "    out_df = pd.DataFrame(new_csv_rows)\n",
        "    out_df.to_csv(os.path.join(save_path, 'labels.csv'), index=False)\n",
        "    return save_path\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "new_cell_2"
      },
      "source": [
        "# ==========================================\n",
        "# 3. DATASET & MODEL CLASSES\n",
        "# ==========================================\n",
        "class CollagenDataset(Dataset):\n",
        "    def __init__(self, file_list, df, fixed_size=FIXED_IMAGE_SIZE):\n",
        "        self.files = file_list\n",
        "        self.df = df\n",
        "        self.fixed_size = fixed_size\n",
        "        # Ensure filename matching column exists\n",
        "        if 'clean_filename' not in self.df.columns:\n",
        "            self.df['clean_filename'] = self.df['filename']\n",
        "\n",
        "    def __len__(self): return len(self.files)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        path = self.files[idx]\n",
        "        fname = os.path.basename(path)\n",
        "\n",
        "        img = tiff.imread(path).astype(np.float32)\n",
        "        # Standardize Input\n",
        "        if img.max() > img.min():\n",
        "            img = (img - img.min()) / (img.max() - img.min() + 1e-8) # Added epsilon\n",
        "\n",
        "        # Ensure image is fixed_size. This handles 'Unmodified' images and ensures consistency\n",
        "        # if there were any issues with previous augmentation steps.\n",
        "        curr_h, curr_w = img.shape\n",
        "        if curr_h < self.fixed_size or curr_w < self.fixed_size:\n",
        "            # Pad if image is smaller than fixed_size\n",
        "            pad_h_before = (self.fixed_size - curr_h) // 2\n",
        "            pad_h_after = self.fixed_size - curr_h - pad_h_before\n",
        "            pad_w_before = (self.fixed_size - curr_w) // 2\n",
        "            pad_w_after = self.fixed_size - curr_w - pad_w_before\n",
        "            img_processed = np.pad(img, ((pad_h_before, pad_h_after), (pad_w_before, pad_w_after)), mode='constant')\n",
        "        else:\n",
        "            # Center crop if image is larger or equal to fixed_size\n",
        "            y_start = (curr_h - self.fixed_size) // 2\n",
        "            x_start = (curr_w - self.fixed_size) // 2\n",
        "            img_processed = img[y_start:y_start+self.fixed_size, x_start:x_start+self.fixed_size]\n",
        "\n",
        "        img_processed = np.expand_dims(img_processed, 0)\n",
        "\n",
        "        # GT Generation\n",
        "        h, w = img_processed.shape[1], img_processed.shape[2] # Use processed image dimensions for GT map\n",
        "        file_data = self.df[self.df['clean_filename'] == fname]\n",
        "\n",
        "        acc_u = np.zeros((h, w), dtype=np.float32)\n",
        "        acc_v = np.zeros((h, w), dtype=np.float32)\n",
        "        mask = np.zeros((h, w), dtype=np.float32)\n",
        "\n",
        "        # `pos` values in the CSVs are now assumed to be adjusted to the `fixed_size` image due to the changes in `generate_rotated_data` and `generate_blurred_data`.\n",
        "        for _, row in file_data.iterrows():\n",
        "            try:\n",
        "                p_str = str(row['pos']) if 'pos' in row else row.iloc[1]\n",
        "                c = [int(x) for x in p_str.replace('(', '').replace(')', '').split(',')]\n",
        "                cy, cx = c[0], c[1]\n",
        "\n",
        "                # REGION_SIZE is 100, so half is 50\n",
        "                start_y, end_y = max(0, cy-REGION_SIZE//2), min(h, cy+REGION_SIZE//2)\n",
        "                start_x, end_x = max(0, cx-REGION_SIZE//2), min(w, cx+REGION_SIZE//2)\n",
        "\n",
        "                u = float(row['u']) if 'u' in row else float(row.iloc[2])\n",
        "                v = float(row['v']) if 'v' in row else float(row.iloc[3])\n",
        "\n",
        "                acc_u[start_y:end_y, start_x:end_x] += u\n",
        "                acc_v[start_y:end_y, start_x:end_x] += v\n",
        "                mask[start_y:end_y, start_x:end_x] = 1.0\n",
        "            except: continue\n",
        "\n",
        "        theta = np.arctan2(acc_v, acc_u + 1e-8)\n",
        "        gt_sin = np.sin(2*theta) * mask\n",
        "        gt_cos = np.cos(2*theta) * mask\n",
        "\n",
        "        return torch.from_numpy(img_processed), torch.from_numpy(np.stack([gt_sin, gt_cos])), torch.from_numpy(mask)\n",
        "\n",
        "class SimpleUNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        # Shallow U-Net for speed\n",
        "        self.enc1 = nn.Sequential(nn.Conv2d(1, 32, 3, 1, 1), nn.ReLU())\n",
        "        self.enc2 = nn.Sequential(nn.Conv2d(32, 64, 3, 1, 1), nn.ReLU())\n",
        "        self.pool = nn.MaxPool2d(2)\n",
        "\n",
        "        self.mid = nn.Sequential(nn.Conv2d(64, 128, 3, 1, 1), nn.ReLU())\n",
        "\n",
        "        self.up2 = nn.ConvTranspose2d(128, 64, 2, 2)\n",
        "        self.dec2 = nn.Conv2d(128, 64, 3, 1, 1)\n",
        "        self.up1 = nn.ConvTranspose2d(64, 32, 2, 2)\n",
        "        self.dec1 = nn.Conv2d(64, 32, 3, 1, 1)\n",
        "        self.out = nn.Conv2d(32, 2, 1) # Sin, Cos\n",
        "\n",
        "    def forward(self, x):\n",
        "        e1 = self.enc1(x)\n",
        "        e2 = self.enc2(self.pool(e1))\n",
        "\n",
        "        m = self.mid(self.pool(e2))\n",
        "\n",
        "        d2 = self.dec2(torch.cat([self.up2(m), e2], 1))\n",
        "        d1 = self.dec1(torch.cat([self.up1(d2), e1], 1))\n",
        "\n",
        "        return F.normalize(self.out(d1), p=2, dim=1)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 457
        },
        "id": "new_cell_3",
        "outputId": "fb8068ef-63d2-4d61-be2c-ded5109eaead"
      },
      "source": [
        "# ==========================================\n",
        "# 4. DATA GENERATION\n",
        "# ==========================================\n",
        "# Load Master CSV\n",
        "csv_path = os.path.join(ORIGINAL_DATA_DIR, CSV_FILENAME)\n",
        "master_df = pd.read_csv(csv_path)\n",
        "master_df['clean_filename'] = master_df.iloc[:, 0].apply(lambda x: os.path.basename(str(x)).strip())\n",
        "\n",
        "# Get all unique Tiff files\n",
        "all_tiffs = sorted(glob.glob(os.path.join(ORIGINAL_DATA_DIR, '*.tiff')))\n",
        "train_files, test_files = train_test_split(all_tiffs, test_size=0.2, random_state=42)\n",
        "\n",
        "print(f\"Split: {len(train_files)} Train, {len(test_files)} Test\")\n",
        "\n",
        "# --- Generate 3 Training Sets ---\n",
        "# 1. Unmodified (Images will be cropped to FIXED_IMAGE_SIZE by CollagenDataset)\n",
        "train_sets = {'Unmodified': (train_files, master_df)}\n",
        "\n",
        "# 2. Rotated\n",
        "rot_path = generate_rotated_data(train_files, master_df, 'Train_Rotated', fixed_size=FIXED_IMAGE_SIZE)\n",
        "rot_df = pd.read_csv(os.path.join(rot_path, 'labels.csv'))\n",
        "rot_files = sorted(glob.glob(os.path.join(rot_path, '*.tiff')))\n",
        "train_sets['Rotated'] = (rot_files, rot_df)\n",
        "\n",
        "# 3. Blurred\n",
        "blur_path = generate_blurred_data(train_files, master_df, 'Train_Blurred', fixed_size=FIXED_IMAGE_SIZE)\n",
        "blur_df = pd.read_csv(os.path.join(blur_path, 'labels.csv'))\n",
        "blur_files = sorted(glob.glob(os.path.join(blur_path, '*.tiff')))\n",
        "train_sets['Blurred'] = (blur_files, blur_df)\n",
        "\n",
        "\n",
        "# --- Generate 3 Test Sets ---\n",
        "test_sets = {'Unmodified': (test_files, master_df)}\n",
        "\n",
        "rot_test_path = generate_rotated_data(test_files, master_df, 'Test_Rotated', fixed_size=FIXED_IMAGE_SIZE)\n",
        "rot_test_df = pd.read_csv(os.path.join(rot_test_path, 'labels.csv'))\n",
        "rot_test_files = sorted(glob.glob(os.path.join(rot_test_path, '*.tiff')))\n",
        "test_sets['Rotated'] = (rot_test_files, rot_test_df)\n",
        "\n",
        "blur_test_path = generate_blurred_data(test_files, master_df, 'Test_Blurred', fixed_size=FIXED_IMAGE_SIZE)\n",
        "blur_test_df = pd.read_csv(os.path.join(blur_test_path, 'labels.csv'))\n",
        "blur_test_files = sorted(glob.glob(os.path.join(blur_test_path, '*.tiff')))\n",
        "test_sets['Blurred'] = (blur_test_files, blur_test_df)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: '/content/drive/Shareddrives/ENM 5310 Group Project/Training Data/fibril_orientation_2d_results.csv'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2176235928.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Load Master CSV\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mcsv_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mORIGINAL_DATA_DIR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCSV_FILENAME\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mmaster_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcsv_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mmaster_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'clean_filename'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmaster_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbasename\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1024\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1026\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1027\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1028\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    619\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 620\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    622\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1619\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1620\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1622\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1879\u001b[0m                     \u001b[0mmode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"b\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1880\u001b[0;31m             self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1881\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1882\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    871\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    872\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 873\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    874\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    875\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/drive/Shareddrives/ENM 5310 Group Project/Training Data/fibril_orientation_2d_results.csv'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "new_cell_4"
      },
      "source": [
        "# ==========================================\n",
        "# 5. MAIN TRAINING & EVALUATION LOOP\n",
        "# ==========================================\n",
        "matrix_results = np.zeros((3, 3)) # Rows: Models, Cols: TestSets\n",
        "model_names = ['Unmodified', 'Rotated', 'Blurred']\n",
        "trained_models = []\n",
        "\n",
        "# --- A. TRAINING PHASE ---\n",
        "for i, m_name in enumerate(model_names):\n",
        "    print(f\"\\nTraining Model: {m_name}...\")\n",
        "\n",
        "    files, df = train_sets[m_name]\n",
        "    dataset = CollagenDataset(files, df, fixed_size=FIXED_IMAGE_SIZE)\n",
        "    loader = DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
        "\n",
        "    model = SimpleUNet().to(DEVICE)\n",
        "    optimizer = optim.Adam(model.parameters(), lr=LR)\n",
        "\n",
        "    # Cosine Loss\n",
        "    criterion = lambda p, t, m: (1 - (p*t).sum(1, keepdim=True) * m).sum() / (m.sum() + 1e-8)\n",
        "\n",
        "    model.train()\n",
        "    for ep in range(EPOCHS):\n",
        "        total_loss = 0\n",
        "        for img, tgt, msk in loader:\n",
        "            img, tgt, msk = img.to(DEVICE), tgt.to(DEVICE), msk.to(DEVICE)\n",
        "            optimizer.zero_grad()\n",
        "            loss = criterion(model(img), tgt, msk)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            total_loss += loss.item()\n",
        "\n",
        "    trained_models.append(model)\n",
        "    torch.save(model.state_dict(), os.path.join(MODEL_SAVE_DIR, f\"model_{m_name}.pth\"))\n",
        "    print(f\"Finished {m_name}. Final Loss: {total_loss/len(loader):.4f}\")\n",
        "\n",
        "# --- B. EVALUATION PHASE (CROSS-MATRIX) ---\n",
        "def get_mae(model, loader):\n",
        "    model.eval()\n",
        "    errors = []\n",
        "    with torch.no_grad():\n",
        "        for img, tgt, msk in loader:\n",
        "            img = img.to(DEVICE)\n",
        "            out = model(img) # (B, 2, H, W)\n",
        "\n",
        "            # Convert back to angles\n",
        "            pred_ang = 0.5 * np.arctan2(out[:,0].cpu().numpy(), out[:,1].cpu().numpy())\n",
        "            gt_ang = 0.5 * np.arctan2(tgt[:,0].numpy(), tgt[:,1].numpy())\n",
        "\n",
        "            # Mask valid regions\n",
        "            mask_np = msk.numpy() == 1\n",
        "\n",
        "            diff = np.abs(np.degrees(pred_ang[mask_np]) - np.degrees(gt_ang[mask_np]))\n",
        "            diff = diff % 180\n",
        "            diff = np.minimum(diff, 180 - diff)\n",
        "            errors.extend(diff)\n",
        "\n",
        "    return np.mean(errors) if len(errors) > 0 else 90.0\n",
        "\n",
        "print(\"\\n--- Generating Cross-Evaluation Matrix ---\")\n",
        "for i, m_name in enumerate(model_names):     # Rows\n",
        "    model = trained_models[i]\n",
        "    for j, t_name in enumerate(model_names): # Cols\n",
        "        files, df = test_sets[t_name]\n",
        "        dset = CollagenDataset(files, df, fixed_size=FIXED_IMAGE_SIZE)\n",
        "        # Use batch_size=4 for evaluation speed\n",
        "        loader = DataLoader(dset, batch_size=4, shuffle=False)\n",
        "\n",
        "        mae = get_mae(model, loader)\n",
        "        matrix_results[i, j] = mae\n",
        "        print(f\"Model[{m_name}] on Test[{t_name}] -> MAE: {mae:.2f}\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "new_cell_5"
      },
      "source": [
        "# ==========================================\n",
        "# 6. VISUALIZATION (CONFUSION MATRIX)\n",
        "# ==========================================\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(matrix_results, annot=True, fmt=\".2f\", cmap=\"RdYlGn_r\",\n",
        "            xticklabels=model_names, yticklabels=model_names)\n",
        "plt.title(\"Cross-Evaluation Matrix (MAE in Degrees)\\nRows=Model Trained On, Cols=Tested On\")\n",
        "plt.xlabel(\"Test Data Type\")\n",
        "plt.ylabel(\"Training Data Type\")\n",
        "plt.tight_layout()\n",
        "plt.savefig(os.path.join(BASE_DIR, 'Evaluation_Matrix.png'))\n",
        "plt.show()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "print(os.listdir('/content/drive/Shareddrives/ENM 5310 Group Project'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "blzdfiG-u0sG",
        "outputId": "00c210fa-933c-44c6-e74a-fd7d97e6781a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Models_v2', 'Experiment_Data_v2']\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}